{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обработка-данных\" data-toc-modified-id=\"Обработка-данных-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обработка данных</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>LogisticRegression</a></span><ul class=\"toc-item\"><li><span><a href=\"#После-ресемплинга-с-уменьшением-класса-0\" data-toc-modified-id=\"После-ресемплинга-с-уменьшением-класса-0-3.1.1\"><span class=\"toc-item-num\">3.1.1&nbsp;&nbsp;</span>После ресемплинга с уменьшением класса 0</a></span></li><li><span><a href=\"#Автоматическая-настройка-весов-'balanced'\" data-toc-modified-id=\"Автоматическая-настройка-весов-'balanced'-3.1.2\"><span class=\"toc-item-num\">3.1.2&nbsp;&nbsp;</span>Автоматическая настройка весов 'balanced'</a></span></li></ul></li><li><span><a href=\"#CatBoost\" data-toc-modified-id=\"CatBoost-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>CatBoost</a></span></li><li><span><a href=\"#DecisionTree\" data-toc-modified-id=\"DecisionTree-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>DecisionTree</a></span><ul class=\"toc-item\"><li><span><a href=\"#После-ресемплинга-с-уменьшением-класса-0\" data-toc-modified-id=\"После-ресемплинга-с-уменьшением-класса-0-3.3.1\"><span class=\"toc-item-num\">3.3.1&nbsp;&nbsp;</span>После ресемплинга с уменьшением класса 0</a></span></li><li><span><a href=\"#Автоматическая-настройка-весов-'balanced'\" data-toc-modified-id=\"Автоматическая-настройка-весов-'balanced'-3.3.2\"><span class=\"toc-item-num\">3.3.2&nbsp;&nbsp;</span>Автоматическая настройка весов 'balanced'</a></span></li></ul></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Тестирование</a></span><ul class=\"toc-item\"><li><span><a href=\"#Проверка-на-адекватность\" data-toc-modified-id=\"Проверка-на-адекватность-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Проверка на адекватность</a></span></li><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>LogisticRegression</a></span><ul class=\"toc-item\"><li><span><a href=\"#После-ресемплинга-с-уменьшением-класса-0\" data-toc-modified-id=\"После-ресемплинга-с-уменьшением-класса-0-4.2.1\"><span class=\"toc-item-num\">4.2.1&nbsp;&nbsp;</span>После ресемплинга с уменьшением класса 0</a></span></li><li><span><a href=\"#Автоматическая-настройка-весов-'balanced'\" data-toc-modified-id=\"Автоматическая-настройка-весов-'balanced'-4.2.2\"><span class=\"toc-item-num\">4.2.2&nbsp;&nbsp;</span>Автоматическая настройка весов 'balanced'</a></span></li></ul></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Выводы</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучить модель классифицировать комментарии на позитивные и негативные. В распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "**Цель:** построить модель со значением метрики качества *AUC-ROC* не меньше 0.85.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные состоят из файлов, полученных из разных источников. Во всех файлах столбец customerID содержит код клиента. Информация о договорах актуальна на 1 февраля 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import warnings\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27235</th>\n",
       "      <td>\"[outdent]David,  I have tried in the nicest p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85350</th>\n",
       "      <td>This is Spitfire \\n\\nI'm a giant douche, that'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17437</th>\n",
       "      <td>Please don't tell me what to do.  The discussi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141674</th>\n",
       "      <td>Hello.\\nSo like a month back I wasn't behaving...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15423</th>\n",
       "      <td>\"\\n\\n Pro-German \\n\\nI think the article shoul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158932</th>\n",
       "      <td>\"\\nInactive bureaucrat?\\nShould bureaucrats th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117484</th>\n",
       "      <td>I had posted this as an edit description but i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134468</th>\n",
       "      <td>Went up several hours ago sorry, it's at Gaza_...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148579</th>\n",
       "      <td>devout Christian and politically conservative....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29928</th>\n",
       "      <td>Don't be dense. -user</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "27235   \"[outdent]David,  I have tried in the nicest p...      0\n",
       "85350   This is Spitfire \\n\\nI'm a giant douche, that'...      1\n",
       "17437   Please don't tell me what to do.  The discussi...      0\n",
       "141674  Hello.\\nSo like a month back I wasn't behaving...      0\n",
       "15423   \"\\n\\n Pro-German \\n\\nI think the article shoul...      0\n",
       "158932  \"\\nInactive bureaucrat?\\nShould bureaucrats th...      0\n",
       "117484  I had posted this as an edit description but i...      0\n",
       "134468  Went up several hours ago sorry, it's at Gaza_...      0\n",
       "148579  devout Christian and politically conservative....      0\n",
       "29928                               Don't be dense. -user      0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv(\"D:/Users/Egor/Desktop/Proga/Jupyter/toxic/toxic_comments.csv\", index_col=0)\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "toxic    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.898388\n",
       "1    0.101612\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "- Данные загружены;\n",
    "- Пропущенных значений и дубликатов нет;\n",
    "- В целевом признаке около 90% объектов отрицательного класса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text)   \n",
    "    text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,             \n",
    "                \"N\": wordnet.NOUN,              \n",
    "                \"V\": wordnet.VERB,              \n",
    "                \"R\": wordnet.ADV                \n",
    "               }  \n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_lemm_text(text):\n",
    "    text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in nltk.word_tokenize(text)]\n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s ju...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>congratulation from me a well use the tool wel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cocksucker before you piss around on my work</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>your vandalism to the matt shirvington article...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sorry if the word nonsense be offensive to you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which be contrar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>fair use rationale for image wonju jpg thanks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bbq be a man and let discus it maybe over the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hey what be it talk what be it an exclusive gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>before you start throw accusation and warning ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>oh and the girl above start her argument with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>juelz santanas age in juelz santana be year ol...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>bye don t look come or think of comming back t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>redirect talk voydan pop georgiev chernodrinski</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the mitsurugi point make no sense why not argu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>don t mean to bother you i see that you re wri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  toxic\n",
       "0   explanation why the edits make under my userna...      0\n",
       "1   d aww he match this background colour i m seem...      0\n",
       "2   hey man i m really not try to edit war it s ju...      0\n",
       "3   more i can t make any real suggestion on impro...      0\n",
       "4   you sir be my hero any chance you remember wha...      0\n",
       "5   congratulation from me a well use the tool wel...      0\n",
       "6        cocksucker before you piss around on my work      1\n",
       "7   your vandalism to the matt shirvington article...      0\n",
       "8   sorry if the word nonsense be offensive to you...      0\n",
       "9   alignment on this subject and which be contrar...      0\n",
       "10  fair use rationale for image wonju jpg thanks ...      0\n",
       "11  bbq be a man and let discus it maybe over the ...      0\n",
       "12  hey what be it talk what be it an exclusive gr...      1\n",
       "13  before you start throw accusation and warning ...      0\n",
       "14  oh and the girl above start her argument with ...      0\n",
       "15  juelz santanas age in juelz santana be year ol...      0\n",
       "16  bye don t look come or think of comming back t...      1\n",
       "17    redirect talk voydan pop georgiev chernodrinski      0\n",
       "18  the mitsurugi point make no sense why not argu...      0\n",
       "19  don t mean to bother you i see that you re wri...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.to_csv('lemm_toxic.csv', index=False)\n",
    "try:\n",
    "    data = pd.read_csv(\"D:/Users/Egor/Desktop/Proga/Jupyter/toxic/lemm_toxic.csv\")\n",
    "except:  \n",
    "    %%time\n",
    "    data['text'] = data['text'].apply(clear_text)\n",
    "    data['text'] = data['text'].apply(get_lemm_text) \n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(['toxic'], axis=1) \n",
    "target = data['toxic']\n",
    "\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=.2, random_state=12345, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность признаков - (127433, 1) и целевого признака - (127433,) обучающей выборки\n",
      "Размерность признаков - (31859, 1) и целевого признака - (31859,) тестовой выборки\n"
     ]
    }
   ],
   "source": [
    "print(f'Размерность признаков - {features_train.shape} и целевого признака - {target_train.shape} обучающей выборки')\n",
    "print(f'Размерность признаков - {features_test.shape} и целевого признака - {target_test.shape} тестовой выборки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Egor\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stopwords = set(nltk_stopwords.words(\"english\"))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "\n",
    "features_train_without_unicode = count_tf_idf.fit_transform(features_train['text'].apply(lambda x: np.str_(x)))\n",
    "features_test_without_unicode = count_tf_idf.transform(features_test['text'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность признаков - (127433, 132707) и целевого признака - (127433,) обучающей выборки\n",
      "Размерность признаков - (31859, 132707) и целевого признака - (31859,) тестовой выборки\n"
     ]
    }
   ],
   "source": [
    "print(f'Размерность признаков - {features_train_without_unicode.shape} и целевого признака - {target_train.shape} обучающей выборки')\n",
    "print(f'Размерность признаков - {features_test_without_unicode.shape} и целевого признака - {target_test.shape} тестовой выборки')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = features_train_without_unicode\n",
    "features_test = features_test_without_unicode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "До уменьшения класса 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.898386\n",
       "1    0.101614\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('До уменьшения класса 0:')\n",
    "target_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.iloc[target_train.index]\n",
    "\n",
    "target_train_0 = train[train['toxic'] == 0]['toxic']\n",
    "target_train_1 = train[train['toxic'] == 1]['toxic']\n",
    "\n",
    "target_train_0_downsample = target_train_0.sample(target_train_1.shape[0], random_state=12345)\n",
    "target_train_downsample = pd.concat([target_train_0_downsample, target_train_1])\n",
    "\n",
    "features_train_downsample = data.iloc[target_train_downsample.index]\n",
    "\n",
    "features_train_downsample, target_train_downsample = shuffle(features_train_downsample, target_train_downsample, random_state=12345)\n",
    "features_train_downsample = count_tf_idf.transform(features_train_downsample['text'].apply(lambda x: np.str_(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "После ресемплинга с уменьшением класса 0:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('После ресемплинга с уменьшением класса 0:')\n",
    "target_train_downsample.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**\n",
    "- Текст прошел через функцию для очистки и лемматизации;\n",
    "- Данные разделены на тренировочную, валидационную и тестовую выборки в отношении 3:1:1;\n",
    "- Проведена векторизацию данных;\n",
    "- В обучающей выборке *downsample* находятся сбалансированные классы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### После ресемплинга с уменьшением класса 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 4, 'solver': 'saga'}\n",
      "Wall time: 46.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logmodel = LogisticRegression(random_state=12345) \n",
    "\n",
    "param = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'saga'], 'C':[2,4,5,6,8,10]}\n",
    "gscv_log = GridSearchCV(logmodel, param, scoring='f1', cv=3, n_jobs=-1)\n",
    "gscv_log.fit(features_train_downsample, target_train_downsample)\n",
    "\n",
    "print(gscv_log.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоматическая настройка весов 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'class_weight': 'balanced', 'solver': 'saga'}\n",
      "Wall time: 3min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "logmodel = LogisticRegression(random_state=12345) \n",
    "\n",
    "param = {'solver':['newton-cg', 'lbfgs', 'liblinear', 'saga'], 'C':[2,4,5,6,8,10], 'class_weight':['balanced']}\n",
    "gscv_log_auto = GridSearchCV(logmodel, param, scoring='f1', cv=3, n_jobs=-1)\n",
    "gscv_log_auto.fit(features_train, target_train)\n",
    "\n",
    "print(gscv_log_auto.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'iterations': 200}\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catmodel = CatBoostClassifier(verbose=False) \n",
    "\n",
    "param = {'iterations':[200]}\n",
    "gscv_cat = GridSearchCV(catmodel, param, scoring='f1', cv=3)\n",
    "gscv_cat.fit(features_train_downsample, target_train_downsample)\n",
    "\n",
    "print(gscv_cat.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### После ресемплинга с уменьшением класса 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 23}\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "treemodel = DecisionTreeClassifier(random_state=12345)\n",
    "param = {'max_depth': [x for x in range(1, 25, 2)]}\n",
    "gscv_tree = GridSearchCV(treemodel, param, scoring='f1', cv=3)\n",
    "gscv_tree.fit(features_train_downsample, target_train_downsample)\n",
    "\n",
    "print(gscv_tree.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоматическая настройка весов 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'class_weight': 'balanced', 'max_depth': 23}\n",
      "Wall time: 12min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "treemodel = DecisionTreeClassifier(random_state=12345)\n",
    "param = {'max_depth': [x for x in range(1, 25, 2)], 'class_weight':['balanced']}\n",
    "gscv_tree_auto = GridSearchCV(treemodel, param, scoring='f1', cv=3)\n",
    "gscv_tree_auto.fit(features_train, target_train)\n",
    "\n",
    "print(gscv_tree_auto.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.888842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression ('balanced')</th>\n",
       "      <td>0.758892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.872715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree</th>\n",
       "      <td>0.710971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTree ('balanced')</th>\n",
       "      <td>0.615863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 f1-score\n",
       "LogisticRegression               0.888842\n",
       "LogisticRegression ('balanced')  0.758892\n",
       "CatBoost                         0.872715\n",
       "DecisionTree                     0.710971\n",
       "DecisionTree ('balanced')        0.615863"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = [[gscv_log.best_score_],\n",
    "      [gscv_log_auto.best_score_],\n",
    "      [gscv_cat.best_score_], \n",
    "      [gscv_tree.best_score_],\n",
    "      [gscv_tree_auto.best_score_]]\n",
    "model = [\"LogisticRegression\", \"LogisticRegression ('balanced')\", \"CatBoost\", \"DecisionTree\", \"DecisionTree ('balanced')\"]\n",
    "pd.DataFrame(data=df, index=model, columns=[\"f1-score\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Среди моделей с хорошей метрикой f1-score можно выделить - CatBoost, LogisticRegression.\n",
    "2. Хуже всего себя показала модель DecisionTree, ее оценка f1 составляет ~ 0.61 и 0.71. Ее точно не стоит рассматривать как финальную.\n",
    "3. LogisticRegression показала себя средне с результатом f1-score = 0.75.\n",
    "\n",
    "Выбираем **LogisticRegression**, так как среди всех моделей она показала лучшую оценку f1-score большую 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на адекватность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 для константной модели: 0.18446546614998857\n"
     ]
    }
   ],
   "source": [
    "dummy = DummyClassifier(strategy=\"constant\", constant=1.0)\n",
    "dummy.fit(features_train, target_train)\n",
    "print('F1 для константной модели:', f1_score(target_test, dummy.predict(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### После ресемплинга с уменьшением класса 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.7088858594621391\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression(random_state=12345, n_jobs=-1, C=4, solver='saga')\n",
    "\n",
    "logmodel.fit(features_train_downsample, target_train_downsample)\n",
    "log_predict = logmodel.predict(features_test)\n",
    "log_test_f1 = f1_score(target_test, log_predict)\n",
    "\n",
    "print('F1 на тестовой выборке:', log_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Автоматическая настройка весов 'balanced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 на тестовой выборке: 0.7729880829777844\n"
     ]
    }
   ],
   "source": [
    "logmodel = LogisticRegression(random_state=12345, n_jobs=-1, C=10, solver='saga', class_weight='balanced')\n",
    "\n",
    "logmodel.fit(features_train, target_train)\n",
    "log_auto_predict = logmodel.predict(features_test)\n",
    "log_auto_test_f1 = f1_score(target_test, log_auto_predict)\n",
    "\n",
    "print('F1 на тестовой выборке:', log_auto_test_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во время проекты были загружены данные, удален лишний столбец. Текст прошел через функцию для очистки и лемматизации. Данные разделены на тренировочную, валидационную и тестовую выборки. Проведена векторизацию данных.\n",
    "\n",
    "1. Среди моделей с хорошей метрикой f1-score можно выделить - CatBoost, LogisticRegression.\n",
    "2. Хуже всего себя показала модель DecisionTree, ее оценка f1 составляет ~ 0.61 и 0.71. Ее точно не стоит рассматривать как финальную.\n",
    "3. LogisticRegression показала себя средне с результатом f1-score = 0.75.\n",
    "\n",
    "Лучшей моделью стала **LogisticRegression** с автоматической настройкой весов *class_weight='balanced'* с f1-score равной 0.773 и параметрами *n_jobs=-1*, *solver='saga'* и *C=10*. Проверку на адекватность модель также прошла успешно (по предсказаниям по константе = 1.0, f1-score = 0.184)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
